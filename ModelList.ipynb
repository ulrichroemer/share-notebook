{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import ode\n",
    "from scipy.stats import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Run this cell to create the Monte Carlo Pi Estimation Model\n",
    "def PiEstimate(N):\n",
    "    # N: Number of Monte Carlo samples\n",
    "    # Setting seed to make the results reproducible, if not the random sample generation will change everytime \n",
    "    np.random.seed(42)\n",
    "    # we execute this piece of code \n",
    "    f = np.zeros(N)\n",
    "    # Drawing uniformly distributed random samples within the domain [-1x1]^2. \"np.random.rand(2,1)\" produces the samples \n",
    "    # only in the 1st quadrant but our domain extends in all 4 quadrants. The value -1 summed to the samples will shift \n",
    "    # the values of both the coordinates to negative values but when the factor 2 multipled to the samples will yield \n",
    "    # samples that spans the entire required domain.\n",
    "    zi = -1 + 2*np.random.rand(N,2)\n",
    "    z_in,z_out=[],[]\n",
    "    plt.figure(figsize = [8,8])\n",
    "    # Integrand-Indicator function\n",
    "    for i,val in enumerate(zi):    \n",
    "        \n",
    "    # Computation of the radius of the sample \n",
    "      ri = np.sqrt(val[0]**2 + val[1]**2)    \n",
    "    \n",
    "    # Checking if the sample drawn is within the unit circle. If yes, f[i] takes the value of 1 else 0.\n",
    "      f[i] = np.int(ri <= 1) \n",
    "      if f[i] == 1:\n",
    "         z_in.append(val)\n",
    "      else:\n",
    "         z_out.append(val)\n",
    "    \n",
    "    z_in,z_out = np.array(z_in),np.array(z_out)     \n",
    "    plt.scatter(x=z_in[:,0],y=z_in[:,1],color = 'r',s = 1)\n",
    "    plt.scatter(x=z_out[:,0],y=z_out[:,1],color = 'b',s = 1)\n",
    "    plt.show()\n",
    "    # Monte Carlo approximation of pi - the factor 4 here is to consider all the 4 quadrants of the circle.\n",
    "    pi_MC = 4*np.sum(f)/N   \n",
    "    # Computing the error between true value and MC approximation\n",
    "    print(\"Monte Carlo error %g\" % (np.abs(pi_MC - np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Convergence(N1): \n",
    "  np.random.seed(42)\n",
    "  Nvalues=[int(N1*0.25),int(N1*0.50),int(N1*0.75),N1]\n",
    "  n = len(Nvalues)\n",
    "\n",
    "# Creating an array to store the values of means and std. dev during the evaluation in the loop.\n",
    "  mu_MC = np.zeros(n)\n",
    "  sig_MC = np.zeros(n)\n",
    "\n",
    "# Looping over the number of N values\n",
    "  for j in range(n):\n",
    "    \n",
    "    # Converting the N values from float to integer datatype\n",
    "    N = np.int(Nvalues[j])\n",
    "    \n",
    "    # Integrand-Indicator function\n",
    "    f = np.zeros(N)\n",
    "    \n",
    "    # Looping over the corresponding N values\n",
    "    for i in range(N):    \n",
    "        zi = -1 + 2*np.random.rand(2,1)  \n",
    "        ri = np.sqrt(zi[0,0]**2 + zi[1,0]**2)   \n",
    "        f[i] = np.int(ri <= 1)  \n",
    "    mu_MC[j] = np.mean(f)   \n",
    "    sig_MC[j] = np.std(f)\n",
    "    \n",
    "  return mu_MC,sig_MC, Nvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotConvergence(mu_MC,sig_MC, Nvalues):\n",
    "   \n",
    "    MC_errors = 5*np.divide(sig_MC,np.sqrt(Nvalues))\n",
    "    fig=plt.figure(figsize=(12,8))\n",
    "# Since there exist some uncertainty in the value of pi approximated by MC method, the confidence levels are given in the\n",
    "# form of error bands around the approximated value represented by the green lines. \n",
    "    plt.errorbar(Nvalues, 4*mu_MC, yerr=MC_errors, label = 'convergence',ecolor = 'g', fmt='-o', capsize = 5, capthick = 2)\n",
    "\n",
    "# The true value is given by the red line\n",
    "    plt.plot(Nvalues,np.pi*np.ones(len(Nvalues)),'r-')\n",
    " \n",
    "# X and Y labels of the graph\n",
    "    plt.ylabel('Value of Pi')\n",
    "    plt.xlabel('N values')\n",
    "    plt.xscale('log')\n",
    "    plt.title('Convergence Study')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Defining the model for the harmonic oscillator with the input parameters as the components of the \n",
    "# random vector Z.\n",
    "def Q(z):\n",
    "    gamma = z[0]    \n",
    "    omega = z[1]\n",
    "    f     = z[2]\n",
    "    k     = z[3]\n",
    "    x0    = z[4]\n",
    "    x1    = z[5]\n",
    "\n",
    "    # We need to define the 2nd order differential equation, which is accomplished by creating an auxillary\n",
    "    # variable u = [x', x] that allows us to convert the system into 1st order ode and the variable val stores [x'', x']. \n",
    "    # Finally the required function is formed and returned.\n",
    "    def f_ode(t,u):\n",
    "        val = np.zeros(2)\n",
    "        val[0] = f*np.cos(omega*t)-gamma*u[0] - k*u[1]\n",
    "        val[1] = u[0]\n",
    "        return val\n",
    "\n",
    "    \n",
    "    # Initial & final values of the time and its step values are defined.\n",
    "    t0 = 0    \n",
    "    t1 = 20    \n",
    "    dt = 0.01    \n",
    "    \n",
    "    # Number of steps \n",
    "    Nt = np.int32(t1/dt)   \n",
    "    \n",
    "    # Creating an array of length number of time steps\n",
    "    t = np.zeros(Nt)    \n",
    "    \n",
    "    # Initial conditions\n",
    "    x_init = [x1,x0]   \n",
    "    \n",
    "    # dopri5 represents a higher order Runge-Kutta method\n",
    "    r = ode(f_ode).set_integrator('dopri5')    \n",
    "    r.set_initial_value([x0,x1],t0)    \n",
    "    \n",
    "    # Time integration\n",
    "    i = 0\n",
    "    x = np.zeros(Nt)\n",
    "    \n",
    "    # Integrating at every time step\n",
    "    while r.successful() and r.t < t1:\n",
    "        r.integrate(r.t + dt)    # integrate on time-interval\n",
    "        \n",
    "        # store time point\n",
    "        t[i] = r.t    \n",
    "        \n",
    "        # store solution\n",
    "        x[i] = r.y[1]    \n",
    "        i += 1 \n",
    "        \n",
    "    # return output quantity   \n",
    "    return x[Nt-1]   \n",
    "#print Q([0.1,0.035,0.1,1,0.5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HarOci(gamma_0,Uncer1,k_0,Uncer2,f_0,Uncer3,omega_0,Uncer4,x0_0,Uncer5,x1_0,Uncer6,var,N):\n",
    "  np.random.seed(32)    # set random number generator to a fixed value\n",
    "  Qi = np.zeros(N)    # stores solution at samples\n",
    "  for i in range(0,N):    # loop over all samples\n",
    "     z = np.random.rand(6)    # 6 RVs sampled from the uniform distribution in [0,1]\n",
    "     gamma = ((1-(var/100))+((var*2*z[0])/100))*gamma_0  if Uncer1 else gamma_0  # RVs with 10% variation around nominal value\n",
    "     omega = ((1-(var/100))+((var*2*z[1])/100))*omega_0  if Uncer2 else omega_0  \n",
    "     f = ((1-(var/100))+((var*2*z[2])/100))*f_0 if Uncer3 else f_0\n",
    "     k = ((1-(var/100))+((var*2*z[3])/100))*k_0 if Uncer4 else k_0\n",
    "     x0 = ((1-(var/100))+((var*2*z[4])/100))*x0_0 if Uncer5 else x0_0\n",
    "     x1 = ((1-(var/100))+((var*2*z[5])/100))*x1_0 if Uncer6 else x1_0\n",
    "     Qi[i] = Q([gamma,omega,f,k,x0,x1])\n",
    "  \n",
    "  plt.figure(figsize=(10,8))\n",
    "  plt.xlabel('Values of the output samples')\n",
    "  plt.ylabel('Frequency of occurrence')  \n",
    "  plt.hist(Qi,bins=20,histtype='bar',ec='black') \n",
    "# Compute statistics and estimated number of samples        \n",
    "  Q_mean = np.mean(Qi)\n",
    "  Q_sig = np.std(Qi)\n",
    "  Q_skew = skew(Qi)\n",
    "  Q_kurt = kurtosis(Qi)\n",
    "  print (\"The mean estimated by MC method is %g\" % Q_mean)\n",
    "  print (\"The standard deviation estimated by MC method is %g\" % Q_sig)\n",
    "  print (\"The skewness of the distribution estimated by MC method is %g\" % Q_skew)\n",
    "  print (\"The kurtosis of the distribution estimated by MC method is %g\" % Q_kurt)\n",
    "  plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cant_Beam(Length,Uncer1,Width,Uncer2,Load,Uncer3,Material,Uncer4,var,N):\n",
    "   np.random.seed(32)\n",
    "   Y=np.zeros(N)\n",
    "   for i in range(0,N):    # loop over all samples\n",
    "     z = np.random.rand(4)\n",
    "     L = ((1-(var/100))+((var*2*z[0])/100))*Length if Uncer1 else Length     # 6 RVs sampled from the uniform distribution in [0,1]\n",
    "     W = ((1-(var/100))+((var*2*z[1])/100))*Width if Uncer2 else Width   # RVs with 10% variation around nominal value\n",
    "     P = ((1-(var/100))+((var*2*z[2])/100))*Load if Uncer3 else Load  \n",
    "     E = ((1-(var/100))+((var*2*z[3])/100))*Material if Uncer4 else Material\n",
    "     I =  (W**4)/12\n",
    "     Y[i]=(P*(L**3))/(3*E*I)\n",
    "     \n",
    "   plt.figure(figsize=(10,8))\n",
    "   plt.xlabel('Values of the output samples')\n",
    "   plt.ylabel('Frequency of occurrence')  \n",
    "   plt.hist(Y,bins=20,histtype='bar',ec='black') \n",
    "    \n",
    "  # Compute statistics and estimated number of samples        \n",
    "   Q_mean = np.mean(Y)\n",
    "   Q_sig = np.std(Y)\n",
    "   Q_skew = skew(Y)\n",
    "   Q_kurt = kurtosis(Y)\n",
    "   print (\"The mean estimated by MC method is %g\" % Q_mean)\n",
    "   print (\"The standard deviation estimated by MC method is %g\" % Q_sig)\n",
    "   print (\"The skewness of the distribution estimated by MC method is %g\" % Q_skew)\n",
    "   print (\"The kurtosis of the distribution estimated by MC method is %g\" % Q_kurt)\n",
    "   plt.show()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Skewness(a,b):\n",
    "   x = np.linspace(skewnorm.ppf(0.01, a),skewnorm.ppf(0.99, a), 100)\n",
    "   xx = np.linspace(skewnorm.ppf(0.01, b),skewnorm.ppf(0.99, b), 100)\n",
    "   plt.figure(figsize=(12,8))\n",
    "   plt.plot(x, skewnorm.pdf(x, a),'r-', lw=2, label='skewed pdf')\n",
    "   plt.plot(xx, skewnorm.pdf(xx, b),'b-', lw=2, label='standard pdf')\n",
    "   plt.legend(fontsize = 'medium')\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KurtPlot(mu,sigma):\n",
    "  #mu = [0,0,0]\n",
    "  #sigma = [0.1,0.05,0.03]\n",
    "  plt.figure(figsize = [12,8])\n",
    "  def plotting(mu,sigma):\n",
    "    \n",
    "    bins = np.linspace(-0.5, 0.5, 1000)\n",
    "    \n",
    "    #pdf of a gaussian distribution\n",
    "    yy = 1/(sigma * np.sqrt(2 * np.pi)) *np.exp( - (bins - mu)**2 / (2 * sigma**2) ) \n",
    "    \n",
    "    # Measuring the kurtosis of the pdf\n",
    "    kurt = kurtosis(yy) \n",
    "\n",
    "    plt.plot(bins,yy,linewidth=2,label='kurtosis=%g'%kurt)\n",
    "    \n",
    "  plotting(mu[0],sigma[0])\n",
    "  plotting(mu[1],sigma[1])\n",
    "  plotting(mu[2],sigma[2])\n",
    "  plt.legend(fontsize = 'medium')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
